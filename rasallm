
What is langchain 
Chromadb 


Rasa + LangChain + ChromaDB

so the project architecture are


rasa_pdf_bot/
â”œâ”€â”€ actions/
â”‚   â””â”€â”€ actions.py           â† Custom action using LangChain + Chroma
â”œâ”€â”€ data/
â”‚   â””â”€â”€ rules.yml            â† Rasa rule for triggering the action
â”œâ”€â”€ domain.yml               â† Intents, actions, responses
â”œâ”€â”€ config.yml               â† Rasa pipeline (keep default or simple)
â”œâ”€â”€ endpoints.yml            â† Enable action server
â”œâ”€â”€ sample.pdf               â† A sample PDF (you provide)



domain.yml

version: "3.1"

intents:
  - ask_question

actions:
  - action_query_pdf_knowledge

responses:
  utter_ask_question:
    - text: "Sure, what would you like to know from the document?"

session_config:
  session_expiration_time: 60
  carry_over_slots_to_new_session: true


data/rules.yml

version: "3.1"

rules:
- rule: Answer PDF-based question
  steps:
    - intent: ask_question
    - action: action_query_pdf_knowledge
ğŸ“„ endpoints.yml

action_endpoint:
  url: "http://localhost:5055/webhook"



actions/actions.py



from rasa_sdk import Action, Tracker
from rasa_sdk.executor import CollectingDispatcher
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
import os

class ActionQueryPdfKnowledge(Action):

    def name(self):
        return "action_query_pdf_knowledge"

    def run(self, dispatcher: CollectingDispatcher,
            tracker: Tracker,
            domain: dict):

        query = tracker.latest_message.get("text")

        # Load and chunk the PDF
        loader = PyPDFLoader("sample.pdf")
        pages = loader.load()
        text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)
        docs = text_splitter.split_documents(pages)

        # Embed using HuggingFace
        embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

        # Setup ChromaDB
        db_dir = "./chroma_storage"
        db = Chroma.from_documents(docs, embeddings, persist_directory=db_dir)
        db.persist()

        # Search for the answer
        results = db.similarity_search(query, k=1)
        answer = results[0].page_content if results else "Sorry, I couldn't find anything relevant in the document."

        dispatcher.utter_message(text=answer)
        return []



  

  then 

  rasa train
  rasa run actions

  rasa shell

  DIETClassifier what is ?     





